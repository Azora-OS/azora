{"version":3,"names":["_openai","_interopRequireDefault","require","_sdk","e","__esModule","default","AIOrchestrator","openai","anthropic","cache","Map","CACHE_TTL","totalTokensUsed","totalCost","constructor","process","env","OPENAI_API_KEY","OpenAI","apiKey","ANTHROPIC_API_KEY","Anthropic","generateCode","prompt","context","model","cacheKey","getCacheKey","cached","getCachedResponse","console","log","content","response","tokensUsed","cost","selectedModel","selectModel","fullPrompt","buildPrompt","provider","generateWithOpenAI","generateWithClaude","cacheResponse","Error","completion","chat","completions","create","messages","role","max_tokens","maxTokens","temperature","choices","message","usage","total_tokens","calculateCost","type","text","input_tokens","output_tokens","taskType","userPrompt","projectInfo","frameworks","length","join","files","file","path","conventions","packageManager","typescript","testing","estimateCost","estimatedTokens","Math","ceil","tokens","pricing","input","output","modelPricing","inputTokens","outputTokens","contextStr","JSON","stringify","map","f","hash","i","char","charCodeAt","toString","key","get","Date","now","timestamp","delete","set","size","firstKey","keys","next","value","getUsageStats","totalTokens","cacheSize","clearCache","clear","exports"],"sources":["AIOrchestrator.ts"],"sourcesContent":["import OpenAI from 'openai';\nimport Anthropic from '@anthropic-ai/sdk';\n\nexport interface AIModel {\n  provider: 'openai' | 'anthropic';\n  model: string;\n  maxTokens: number;\n  temperature: number;\n}\n\nexport interface AIContext {\n  files: Array<{ path: string; content: string }>;\n  projectInfo: {\n    frameworks: string[];\n    conventions: any;\n  };\n  userPrompt: string;\n}\n\nexport interface AIResponse {\n  content: string;\n  model: string;\n  tokensUsed: number;\n  cost: number;\n}\n\nexport interface CachedResponse {\n  prompt: string;\n  response: string;\n  timestamp: number;\n  model: string;\n}\n\nexport class AIOrchestrator {\n  private openai: OpenAI | null = null;\n  private anthropic: Anthropic | null = null;\n  private cache: Map<string, CachedResponse> = new Map();\n  private readonly CACHE_TTL = 3600000; // 1 hour\n  private totalTokensUsed = 0;\n  private totalCost = 0;\n\n  constructor() {\n    // Initialize clients if API keys are available\n    if (process.env.OPENAI_API_KEY) {\n      this.openai = new OpenAI({\n        apiKey: process.env.OPENAI_API_KEY,\n      });\n    }\n\n    if (process.env.ANTHROPIC_API_KEY) {\n      this.anthropic = new Anthropic({\n        apiKey: process.env.ANTHROPIC_API_KEY,\n      });\n    }\n  }\n\n  async generateCode(prompt: string, context: AIContext, model?: AIModel): Promise<AIResponse> {\n    // Check cache first\n    const cacheKey = this.getCacheKey(prompt, context);\n    const cached = this.getCachedResponse(cacheKey);\n    if (cached) {\n      console.log('Using cached AI response');\n      return {\n        content: cached.response,\n        model: cached.model,\n        tokensUsed: 0,\n        cost: 0,\n      };\n    }\n\n    // Select model\n    const selectedModel = model || this.selectModel('code-generation');\n\n    // Build full prompt with context\n    const fullPrompt = this.buildPrompt(prompt, context);\n\n    // Generate response\n    let response: AIResponse;\n    if (selectedModel.provider === 'openai') {\n      response = await this.generateWithOpenAI(fullPrompt, selectedModel);\n    } else {\n      response = await this.generateWithClaude(fullPrompt, selectedModel);\n    }\n\n    // Cache response\n    this.cacheResponse(cacheKey, response.content, response.model);\n\n    // Track usage\n    this.totalTokensUsed += response.tokensUsed;\n    this.totalCost += response.cost;\n\n    return response;\n  }\n\n  private async generateWithOpenAI(prompt: string, model: AIModel): Promise<AIResponse> {\n    if (!this.openai) {\n      throw new Error('OpenAI client not initialized. Please set OPENAI_API_KEY.');\n    }\n\n    const completion = await this.openai.chat.completions.create({\n      model: model.model,\n      messages: [\n        {\n          role: 'system',\n          content: 'You are an expert software developer assistant. Generate clean, production-ready code following best practices.',\n        },\n        {\n          role: 'user',\n          content: prompt,\n        },\n      ],\n      max_tokens: model.maxTokens,\n      temperature: model.temperature,\n    });\n\n    const content = completion.choices[0]?.message?.content || '';\n    const tokensUsed = completion.usage?.total_tokens || 0;\n    const cost = this.calculateCost('openai', model.model, tokensUsed);\n\n    return {\n      content,\n      model: model.model,\n      tokensUsed,\n      cost,\n    };\n  }\n\n  private async generateWithClaude(prompt: string, model: AIModel): Promise<AIResponse> {\n    if (!this.anthropic) {\n      throw new Error('Anthropic client not initialized. Please set ANTHROPIC_API_KEY.');\n    }\n\n    const message = await this.anthropic.messages.create({\n      model: model.model,\n      max_tokens: model.maxTokens,\n      temperature: model.temperature,\n      messages: [\n        {\n          role: 'user',\n          content: prompt,\n        },\n      ],\n    });\n\n    const content = message.content[0]?.type === 'text' ? message.content[0].text : '';\n    const tokensUsed = message.usage.input_tokens + message.usage.output_tokens;\n    const cost = this.calculateCost('anthropic', model.model, tokensUsed);\n\n    return {\n      content,\n      model: model.model,\n      tokensUsed,\n      cost,\n    };\n  }\n\n  selectModel(taskType: string): AIModel {\n    // Select appropriate model based on task type\n    switch (taskType) {\n      case 'code-generation':\n        return {\n          provider: 'openai',\n          model: 'gpt-4-turbo-preview',\n          maxTokens: 4096,\n          temperature: 0.2,\n        };\n      case 'refactoring':\n        return {\n          provider: 'anthropic',\n          model: 'claude-3-opus-20240229',\n          maxTokens: 4096,\n          temperature: 0.1,\n        };\n      case 'explanation':\n        return {\n          provider: 'openai',\n          model: 'gpt-4-turbo-preview',\n          maxTokens: 2048,\n          temperature: 0.7,\n        };\n      default:\n        return {\n          provider: 'openai',\n          model: 'gpt-4-turbo-preview',\n          maxTokens: 4096,\n          temperature: 0.3,\n        };\n    }\n  }\n\n  private buildPrompt(userPrompt: string, context: AIContext): string {\n    let prompt = `# Task\\n${userPrompt}\\n\\n`;\n\n    // Add project context\n    if (context.projectInfo.frameworks.length > 0) {\n      prompt += `# Project Frameworks\\n${context.projectInfo.frameworks.join(', ')}\\n\\n`;\n    }\n\n    // Add relevant files\n    if (context.files.length > 0) {\n      prompt += `# Relevant Files\\n\\n`;\n      for (const file of context.files) {\n        prompt += `## ${file.path}\\n\\`\\`\\`\\n${file.content}\\n\\`\\`\\`\\n\\n`;\n      }\n    }\n\n    // Add conventions\n    if (context.projectInfo.conventions) {\n      prompt += `# Project Conventions\\n`;\n      prompt += `- Package Manager: ${context.projectInfo.conventions.packageManager}\\n`;\n      prompt += `- TypeScript: ${context.projectInfo.conventions.typescript ? 'Yes' : 'No'}\\n`;\n      if (context.projectInfo.conventions.testing.length > 0) {\n        prompt += `- Testing: ${context.projectInfo.conventions.testing.join(', ')}\\n`;\n      }\n      prompt += `\\n`;\n    }\n\n    prompt += `# Instructions\\n`;\n    prompt += `- Generate clean, production-ready code\\n`;\n    prompt += `- Follow the project's existing patterns and conventions\\n`;\n    prompt += `- Include proper error handling\\n`;\n    prompt += `- Add TypeScript types where applicable\\n`;\n    prompt += `- Write self-documenting code with clear variable names\\n`;\n\n    return prompt;\n  }\n\n  async estimateCost(prompt: string, context: AIContext): Promise<number> {\n    const fullPrompt = this.buildPrompt(prompt, context);\n    const estimatedTokens = Math.ceil(fullPrompt.length / 4); // Rough estimate: 1 token â‰ˆ 4 chars\n    const model = this.selectModel('code-generation');\n    return this.calculateCost(model.provider, model.model, estimatedTokens);\n  }\n\n  private calculateCost(provider: string, model: string, tokens: number): number {\n    // Pricing per 1M tokens (as of 2024)\n    const pricing: Record<string, { input: number; output: number }> = {\n      'gpt-4-turbo-preview': { input: 10, output: 30 },\n      'gpt-4': { input: 30, output: 60 },\n      'gpt-3.5-turbo': { input: 0.5, output: 1.5 },\n      'claude-3-opus-20240229': { input: 15, output: 75 },\n      'claude-3-sonnet-20240229': { input: 3, output: 15 },\n    };\n\n    const modelPricing = pricing[model] || { input: 10, output: 30 };\n    // Assume 50/50 split between input and output tokens\n    const inputTokens = tokens * 0.5;\n    const outputTokens = tokens * 0.5;\n    \n    return (inputTokens * modelPricing.input + outputTokens * modelPricing.output) / 1000000;\n  }\n\n  private getCacheKey(prompt: string, context: AIContext): string {\n    const contextStr = JSON.stringify({\n      prompt,\n      files: context.files.map(f => f.path),\n      frameworks: context.projectInfo.frameworks,\n    });\n    \n    // Simple hash function\n    let hash = 0;\n    for (let i = 0; i < contextStr.length; i++) {\n      const char = contextStr.charCodeAt(i);\n      hash = ((hash << 5) - hash) + char;\n      hash = hash & hash;\n    }\n    return hash.toString(36);\n  }\n\n  getCachedResponse(key: string): CachedResponse | null {\n    const cached = this.cache.get(key);\n    if (!cached) return null;\n\n    // Check if cache is still valid\n    if (Date.now() - cached.timestamp > this.CACHE_TTL) {\n      this.cache.delete(key);\n      return null;\n    }\n\n    return cached;\n  }\n\n  cacheResponse(key: string, response: string, model: string): void {\n    this.cache.set(key, {\n      prompt: key,\n      response,\n      timestamp: Date.now(),\n      model,\n    });\n\n    // Limit cache size\n    if (this.cache.size > 100) {\n      const firstKey = this.cache.keys().next().value;\n      this.cache.delete(firstKey);\n    }\n  }\n\n  getUsageStats(): { totalTokens: number; totalCost: number; cacheSize: number } {\n    return {\n      totalTokens: this.totalTokensUsed,\n      totalCost: this.totalCost,\n      cacheSize: this.cache.size,\n    };\n  }\n\n  clearCache(): void {\n    this.cache.clear();\n  }\n}\n"],"mappings":";;;;;;AAAA,IAAAA,OAAA,GAAAC,sBAAA,CAAAC,OAAA;AACA,IAAAC,IAAA,GAAAF,sBAAA,CAAAC,OAAA;AAA0C,SAAAD,uBAAAG,CAAA,WAAAA,CAAA,IAAAA,CAAA,CAAAC,UAAA,GAAAD,CAAA,KAAAE,OAAA,EAAAF,CAAA;AAgCnC,MAAMG,cAAc,CAAC;EAClBC,MAAM,GAAkB,IAAI;EAC5BC,SAAS,GAAqB,IAAI;EAClCC,KAAK,GAAgC,IAAIC,GAAG,CAAC,CAAC;EACrCC,SAAS,GAAG,OAAO,CAAC,CAAC;EAC9BC,eAAe,GAAG,CAAC;EACnBC,SAAS,GAAG,CAAC;EAErBC,WAAWA,CAAA,EAAG;IACZ;IACA,IAAIC,OAAO,CAACC,GAAG,CAACC,cAAc,EAAE;MAC9B,IAAI,CAACV,MAAM,GAAG,IAAIW,eAAM,CAAC;QACvBC,MAAM,EAAEJ,OAAO,CAACC,GAAG,CAACC;MACtB,CAAC,CAAC;IACJ;IAEA,IAAIF,OAAO,CAACC,GAAG,CAACI,iBAAiB,EAAE;MACjC,IAAI,CAACZ,SAAS,GAAG,IAAIa,YAAS,CAAC;QAC7BF,MAAM,EAAEJ,OAAO,CAACC,GAAG,CAACI;MACtB,CAAC,CAAC;IACJ;EACF;EAEA,MAAME,YAAYA,CAACC,MAAc,EAAEC,OAAkB,EAAEC,KAAe,EAAuB;IAC3F;IACA,MAAMC,QAAQ,GAAG,IAAI,CAACC,WAAW,CAACJ,MAAM,EAAEC,OAAO,CAAC;IAClD,MAAMI,MAAM,GAAG,IAAI,CAACC,iBAAiB,CAACH,QAAQ,CAAC;IAC/C,IAAIE,MAAM,EAAE;MACVE,OAAO,CAACC,GAAG,CAAC,0BAA0B,CAAC;MACvC,OAAO;QACLC,OAAO,EAAEJ,MAAM,CAACK,QAAQ;QACxBR,KAAK,EAAEG,MAAM,CAACH,KAAK;QACnBS,UAAU,EAAE,CAAC;QACbC,IAAI,EAAE;MACR,CAAC;IACH;;IAEA;IACA,MAAMC,aAAa,GAAGX,KAAK,IAAI,IAAI,CAACY,WAAW,CAAC,iBAAiB,CAAC;;IAElE;IACA,MAAMC,UAAU,GAAG,IAAI,CAACC,WAAW,CAAChB,MAAM,EAAEC,OAAO,CAAC;;IAEpD;IACA,IAAIS,QAAoB;IACxB,IAAIG,aAAa,CAACI,QAAQ,KAAK,QAAQ,EAAE;MACvCP,QAAQ,GAAG,MAAM,IAAI,CAACQ,kBAAkB,CAACH,UAAU,EAAEF,aAAa,CAAC;IACrE,CAAC,MAAM;MACLH,QAAQ,GAAG,MAAM,IAAI,CAACS,kBAAkB,CAACJ,UAAU,EAAEF,aAAa,CAAC;IACrE;;IAEA;IACA,IAAI,CAACO,aAAa,CAACjB,QAAQ,EAAEO,QAAQ,CAACD,OAAO,EAAEC,QAAQ,CAACR,KAAK,CAAC;;IAE9D;IACA,IAAI,CAACb,eAAe,IAAIqB,QAAQ,CAACC,UAAU;IAC3C,IAAI,CAACrB,SAAS,IAAIoB,QAAQ,CAACE,IAAI;IAE/B,OAAOF,QAAQ;EACjB;EAEA,MAAcQ,kBAAkBA,CAAClB,MAAc,EAAEE,KAAc,EAAuB;IACpF,IAAI,CAAC,IAAI,CAAClB,MAAM,EAAE;MAChB,MAAM,IAAIqC,KAAK,CAAC,2DAA2D,CAAC;IAC9E;IAEA,MAAMC,UAAU,GAAG,MAAM,IAAI,CAACtC,MAAM,CAACuC,IAAI,CAACC,WAAW,CAACC,MAAM,CAAC;MAC3DvB,KAAK,EAAEA,KAAK,CAACA,KAAK;MAClBwB,QAAQ,EAAE,CACR;QACEC,IAAI,EAAE,QAAQ;QACdlB,OAAO,EAAE;MACX,CAAC,EACD;QACEkB,IAAI,EAAE,MAAM;QACZlB,OAAO,EAAET;MACX,CAAC,CACF;MACD4B,UAAU,EAAE1B,KAAK,CAAC2B,SAAS;MAC3BC,WAAW,EAAE5B,KAAK,CAAC4B;IACrB,CAAC,CAAC;IAEF,MAAMrB,OAAO,GAAGa,UAAU,CAACS,OAAO,CAAC,CAAC,CAAC,EAAEC,OAAO,EAAEvB,OAAO,IAAI,EAAE;IAC7D,MAAME,UAAU,GAAGW,UAAU,CAACW,KAAK,EAAEC,YAAY,IAAI,CAAC;IACtD,MAAMtB,IAAI,GAAG,IAAI,CAACuB,aAAa,CAAC,QAAQ,EAAEjC,KAAK,CAACA,KAAK,EAAES,UAAU,CAAC;IAElE,OAAO;MACLF,OAAO;MACPP,KAAK,EAAEA,KAAK,CAACA,KAAK;MAClBS,UAAU;MACVC;IACF,CAAC;EACH;EAEA,MAAcO,kBAAkBA,CAACnB,MAAc,EAAEE,KAAc,EAAuB;IACpF,IAAI,CAAC,IAAI,CAACjB,SAAS,EAAE;MACnB,MAAM,IAAIoC,KAAK,CAAC,iEAAiE,CAAC;IACpF;IAEA,MAAMW,OAAO,GAAG,MAAM,IAAI,CAAC/C,SAAS,CAACyC,QAAQ,CAACD,MAAM,CAAC;MACnDvB,KAAK,EAAEA,KAAK,CAACA,KAAK;MAClB0B,UAAU,EAAE1B,KAAK,CAAC2B,SAAS;MAC3BC,WAAW,EAAE5B,KAAK,CAAC4B,WAAW;MAC9BJ,QAAQ,EAAE,CACR;QACEC,IAAI,EAAE,MAAM;QACZlB,OAAO,EAAET;MACX,CAAC;IAEL,CAAC,CAAC;IAEF,MAAMS,OAAO,GAAGuB,OAAO,CAACvB,OAAO,CAAC,CAAC,CAAC,EAAE2B,IAAI,KAAK,MAAM,GAAGJ,OAAO,CAACvB,OAAO,CAAC,CAAC,CAAC,CAAC4B,IAAI,GAAG,EAAE;IAClF,MAAM1B,UAAU,GAAGqB,OAAO,CAACC,KAAK,CAACK,YAAY,GAAGN,OAAO,CAACC,KAAK,CAACM,aAAa;IAC3E,MAAM3B,IAAI,GAAG,IAAI,CAACuB,aAAa,CAAC,WAAW,EAAEjC,KAAK,CAACA,KAAK,EAAES,UAAU,CAAC;IAErE,OAAO;MACLF,OAAO;MACPP,KAAK,EAAEA,KAAK,CAACA,KAAK;MAClBS,UAAU;MACVC;IACF,CAAC;EACH;EAEAE,WAAWA,CAAC0B,QAAgB,EAAW;IACrC;IACA,QAAQA,QAAQ;MACd,KAAK,iBAAiB;QACpB,OAAO;UACLvB,QAAQ,EAAE,QAAQ;UAClBf,KAAK,EAAE,qBAAqB;UAC5B2B,SAAS,EAAE,IAAI;UACfC,WAAW,EAAE;QACf,CAAC;MACH,KAAK,aAAa;QAChB,OAAO;UACLb,QAAQ,EAAE,WAAW;UACrBf,KAAK,EAAE,wBAAwB;UAC/B2B,SAAS,EAAE,IAAI;UACfC,WAAW,EAAE;QACf,CAAC;MACH,KAAK,aAAa;QAChB,OAAO;UACLb,QAAQ,EAAE,QAAQ;UAClBf,KAAK,EAAE,qBAAqB;UAC5B2B,SAAS,EAAE,IAAI;UACfC,WAAW,EAAE;QACf,CAAC;MACH;QACE,OAAO;UACLb,QAAQ,EAAE,QAAQ;UAClBf,KAAK,EAAE,qBAAqB;UAC5B2B,SAAS,EAAE,IAAI;UACfC,WAAW,EAAE;QACf,CAAC;IACL;EACF;EAEQd,WAAWA,CAACyB,UAAkB,EAAExC,OAAkB,EAAU;IAClE,IAAID,MAAM,GAAG,WAAWyC,UAAU,MAAM;;IAExC;IACA,IAAIxC,OAAO,CAACyC,WAAW,CAACC,UAAU,CAACC,MAAM,GAAG,CAAC,EAAE;MAC7C5C,MAAM,IAAI,yBAAyBC,OAAO,CAACyC,WAAW,CAACC,UAAU,CAACE,IAAI,CAAC,IAAI,CAAC,MAAM;IACpF;;IAEA;IACA,IAAI5C,OAAO,CAAC6C,KAAK,CAACF,MAAM,GAAG,CAAC,EAAE;MAC5B5C,MAAM,IAAI,sBAAsB;MAChC,KAAK,MAAM+C,IAAI,IAAI9C,OAAO,CAAC6C,KAAK,EAAE;QAChC9C,MAAM,IAAI,MAAM+C,IAAI,CAACC,IAAI,aAAaD,IAAI,CAACtC,OAAO,cAAc;MAClE;IACF;;IAEA;IACA,IAAIR,OAAO,CAACyC,WAAW,CAACO,WAAW,EAAE;MACnCjD,MAAM,IAAI,yBAAyB;MACnCA,MAAM,IAAI,sBAAsBC,OAAO,CAACyC,WAAW,CAACO,WAAW,CAACC,cAAc,IAAI;MAClFlD,MAAM,IAAI,iBAAiBC,OAAO,CAACyC,WAAW,CAACO,WAAW,CAACE,UAAU,GAAG,KAAK,GAAG,IAAI,IAAI;MACxF,IAAIlD,OAAO,CAACyC,WAAW,CAACO,WAAW,CAACG,OAAO,CAACR,MAAM,GAAG,CAAC,EAAE;QACtD5C,MAAM,IAAI,cAAcC,OAAO,CAACyC,WAAW,CAACO,WAAW,CAACG,OAAO,CAACP,IAAI,CAAC,IAAI,CAAC,IAAI;MAChF;MACA7C,MAAM,IAAI,IAAI;IAChB;IAEAA,MAAM,IAAI,kBAAkB;IAC5BA,MAAM,IAAI,2CAA2C;IACrDA,MAAM,IAAI,4DAA4D;IACtEA,MAAM,IAAI,mCAAmC;IAC7CA,MAAM,IAAI,2CAA2C;IACrDA,MAAM,IAAI,2DAA2D;IAErE,OAAOA,MAAM;EACf;EAEA,MAAMqD,YAAYA,CAACrD,MAAc,EAAEC,OAAkB,EAAmB;IACtE,MAAMc,UAAU,GAAG,IAAI,CAACC,WAAW,CAAChB,MAAM,EAAEC,OAAO,CAAC;IACpD,MAAMqD,eAAe,GAAGC,IAAI,CAACC,IAAI,CAACzC,UAAU,CAAC6B,MAAM,GAAG,CAAC,CAAC,CAAC,CAAC;IAC1D,MAAM1C,KAAK,GAAG,IAAI,CAACY,WAAW,CAAC,iBAAiB,CAAC;IACjD,OAAO,IAAI,CAACqB,aAAa,CAACjC,KAAK,CAACe,QAAQ,EAAEf,KAAK,CAACA,KAAK,EAAEoD,eAAe,CAAC;EACzE;EAEQnB,aAAaA,CAAClB,QAAgB,EAAEf,KAAa,EAAEuD,MAAc,EAAU;IAC7E;IACA,MAAMC,OAA0D,GAAG;MACjE,qBAAqB,EAAE;QAAEC,KAAK,EAAE,EAAE;QAAEC,MAAM,EAAE;MAAG,CAAC;MAChD,OAAO,EAAE;QAAED,KAAK,EAAE,EAAE;QAAEC,MAAM,EAAE;MAAG,CAAC;MAClC,eAAe,EAAE;QAAED,KAAK,EAAE,GAAG;QAAEC,MAAM,EAAE;MAAI,CAAC;MAC5C,wBAAwB,EAAE;QAAED,KAAK,EAAE,EAAE;QAAEC,MAAM,EAAE;MAAG,CAAC;MACnD,0BAA0B,EAAE;QAAED,KAAK,EAAE,CAAC;QAAEC,MAAM,EAAE;MAAG;IACrD,CAAC;IAED,MAAMC,YAAY,GAAGH,OAAO,CAACxD,KAAK,CAAC,IAAI;MAAEyD,KAAK,EAAE,EAAE;MAAEC,MAAM,EAAE;IAAG,CAAC;IAChE;IACA,MAAME,WAAW,GAAGL,MAAM,GAAG,GAAG;IAChC,MAAMM,YAAY,GAAGN,MAAM,GAAG,GAAG;IAEjC,OAAO,CAACK,WAAW,GAAGD,YAAY,CAACF,KAAK,GAAGI,YAAY,GAAGF,YAAY,CAACD,MAAM,IAAI,OAAO;EAC1F;EAEQxD,WAAWA,CAACJ,MAAc,EAAEC,OAAkB,EAAU;IAC9D,MAAM+D,UAAU,GAAGC,IAAI,CAACC,SAAS,CAAC;MAChClE,MAAM;MACN8C,KAAK,EAAE7C,OAAO,CAAC6C,KAAK,CAACqB,GAAG,CAACC,CAAC,IAAIA,CAAC,CAACpB,IAAI,CAAC;MACrCL,UAAU,EAAE1C,OAAO,CAACyC,WAAW,CAACC;IAClC,CAAC,CAAC;;IAEF;IACA,IAAI0B,IAAI,GAAG,CAAC;IACZ,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGN,UAAU,CAACpB,MAAM,EAAE0B,CAAC,EAAE,EAAE;MAC1C,MAAMC,IAAI,GAAGP,UAAU,CAACQ,UAAU,CAACF,CAAC,CAAC;MACrCD,IAAI,GAAI,CAACA,IAAI,IAAI,CAAC,IAAIA,IAAI,GAAIE,IAAI;MAClCF,IAAI,GAAGA,IAAI,GAAGA,IAAI;IACpB;IACA,OAAOA,IAAI,CAACI,QAAQ,CAAC,EAAE,CAAC;EAC1B;EAEAnE,iBAAiBA,CAACoE,GAAW,EAAyB;IACpD,MAAMrE,MAAM,GAAG,IAAI,CAACnB,KAAK,CAACyF,GAAG,CAACD,GAAG,CAAC;IAClC,IAAI,CAACrE,MAAM,EAAE,OAAO,IAAI;;IAExB;IACA,IAAIuE,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGxE,MAAM,CAACyE,SAAS,GAAG,IAAI,CAAC1F,SAAS,EAAE;MAClD,IAAI,CAACF,KAAK,CAAC6F,MAAM,CAACL,GAAG,CAAC;MACtB,OAAO,IAAI;IACb;IAEA,OAAOrE,MAAM;EACf;EAEAe,aAAaA,CAACsD,GAAW,EAAEhE,QAAgB,EAAER,KAAa,EAAQ;IAChE,IAAI,CAAChB,KAAK,CAAC8F,GAAG,CAACN,GAAG,EAAE;MAClB1E,MAAM,EAAE0E,GAAG;MACXhE,QAAQ;MACRoE,SAAS,EAAEF,IAAI,CAACC,GAAG,CAAC,CAAC;MACrB3E;IACF,CAAC,CAAC;;IAEF;IACA,IAAI,IAAI,CAAChB,KAAK,CAAC+F,IAAI,GAAG,GAAG,EAAE;MACzB,MAAMC,QAAQ,GAAG,IAAI,CAAChG,KAAK,CAACiG,IAAI,CAAC,CAAC,CAACC,IAAI,CAAC,CAAC,CAACC,KAAK;MAC/C,IAAI,CAACnG,KAAK,CAAC6F,MAAM,CAACG,QAAQ,CAAC;IAC7B;EACF;EAEAI,aAAaA,CAAA,EAAkE;IAC7E,OAAO;MACLC,WAAW,EAAE,IAAI,CAAClG,eAAe;MACjCC,SAAS,EAAE,IAAI,CAACA,SAAS;MACzBkG,SAAS,EAAE,IAAI,CAACtG,KAAK,CAAC+F;IACxB,CAAC;EACH;EAEAQ,UAAUA,CAAA,EAAS;IACjB,IAAI,CAACvG,KAAK,CAACwG,KAAK,CAAC,CAAC;EACpB;AACF;AAACC,OAAA,CAAA5G,cAAA,GAAAA,cAAA","ignoreList":[]}