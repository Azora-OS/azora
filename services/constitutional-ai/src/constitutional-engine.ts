import { z } from 'zod';
import { LLMService } from './llm-service';

// Schema for an Action that needs validation
export const ActionSchema = z.object({
    type: z.string(),
    actorId: z.string(),
    targetId: z.string().optional(),
    payload: z.any(),
    context: z.string().optional(),
});

export type Action = z.infer<typeof ActionSchema>;

export interface ValidationResult {
    isAllowed: boolean;
    score: number; // 0-100
    critique: string;
    violations: string[];
}

export class ConstitutionalEngine {
    private llmService: LLMService;

    constructor() {
        this.llmService = new LLMService();
    }

    /**
     * Validates an action against the Constitution using LLM reasoning.
     * @param action The action to validate.
     * @returns A validation result.
     */
    async validateAction(action: Action): Promise<ValidationResult> {
        // 1. Basic Schema Validation
        const parseResult = ActionSchema.safeParse(action);
        if (!parseResult.success) {
            return {
                isAllowed: false,
                score: 0,
                critique: "Action schema invalid.",
                violations: ["Invalid Schema"]
            };
        }

        // 2. LLM-Based Constitutional Evaluation
        try {
            console.log(`[ConstitutionalEngine] Evaluating action: ${action.type}`);
            const evaluation = await this.llmService.evaluateAction(action);

            return {
                isAllowed: evaluation.isAllowed,
                score: evaluation.score,
                critique: evaluation.critique,
                violations: evaluation.violations || []
            };
        } catch (error) {
            console.error('Constitutional evaluation failed:', error);
            // Fail safe: If the judge is offline, block critical actions
            return {
                isAllowed: false,
                score: 0,
                critique: "Constitutional Engine Error: Unable to evaluate.",
                violations: ["System Error"]
            };
        }
    }

    /**
     * Generates a self-critique of an AI response.
     * @param response The text response generated by an AI.
     * @returns A critique string.
     */
    async generateConstitutionalCritique(response: string): Promise<string> {
        const biasCheck = await this.llmService.detectBias(response);
        if (biasCheck.hasBias) {
            return `Critique: Potential bias detected. ${biasCheck.explanation}`;
        }
        return "Critique: Response aligns with constitutional principles.";
    }

    /**
     * Processes a request for the AI Tutor.
     * @param courseName The name of the course.
     * @param topic The current topic.
     * @param userMessage The student's message.
     * @returns The AI Tutor's response.
     */
    async processTutorRequest(courseName: string, topic: string, userMessage: string): Promise<string> {
        // 1. Construct the prompt
        const systemPrompt = (await import('./prompts')).TUTOR_SYSTEM_PROMPT
            .replace('{{COURSE_NAME}}', courseName)
            .replace('{{TOPIC}}', topic);

        // 2. Call LLM
        try {
            // We use the LLM service directly here, bypassing the strict JSON format of evaluateAction
            // This assumes the LLM adapter can handle standard chat completions too
            // For now, we'll reuse the adapter but we might need to adjust the adapter interface 
            // if we want to enforce JSON for actions but text for chat.
            // The current MockAdapter returns JSON strings, so we need to handle that.

            // Hack: We'll wrap the user message to ask for a JSON response with a "response" field
            // to keep consistent with the current adapter implementation.
            const prompt = `Student: ${userMessage}\n\nRespond as the AI Tutor in JSON format: { "response": "your text here" }`;

            const result = await this.llmService['adapter'].complete(prompt, systemPrompt);
            try {
                const parsed = JSON.parse(result.content);
                return parsed.response || result.content;
            } catch (e) {
                return result.content;
            }
        } catch (error) {
            console.error('Tutor request failed:', error);
            return "I apologize, but I am having trouble connecting to the planetary mind right now. Please try again later.";
        }
    }
}
